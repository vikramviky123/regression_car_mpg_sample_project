{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"font-size:100%;padding:10px 0px 10px 30px;font-weight: 400;font-family:serifs; letter-spacing: 2px; border: 3px solid yellow; color: brown; background-color:#d3d3d3; border-radius:30px 0px\">1.Importing Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor, VotingRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GroupKFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "from colorama import Style, Fore\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "gld = Style.BRIGHT + Fore.YELLOW\n",
    "grn = Style.BRIGHT + Fore.GREEN\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "white = Style.BRIGHT +Fore.WHITE\n",
    "cyan = Style.BRIGHT +Fore.CYAN\n",
    "magenta = Style.BRIGHT +Fore.MAGENTA\n",
    "res = Style.RESET_ALL\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 800\n",
    "plt.rcParams['savefig.dpi'] = 800\n",
    "\n",
    "sns.set(rc={\"figure.dpi\":800, 'savefig.dpi':800})\n",
    "sns.set_context('notebook')\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "font_title = {\n",
    "    'size': 20,\n",
    "    'weight': 'bold',  # You can use 'weight' here instead of 'fontweight'\n",
    "    'color': 'brown',\n",
    "    'fontfamily': 'serif'\n",
    "}\n",
    "font_sub_title = {'family': 'serif',\n",
    "        'color':  'brown',\n",
    "        'weight': 'bold',\n",
    "        'size': 16,\n",
    "        }\n",
    "font_label = {'family': 'serif',\n",
    "        'color':  'brown',\n",
    "        'weight': 'bold',\n",
    "        'size': 16,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>acc</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_type</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cyl   disp   hp    wt   acc  yr  origin  car_type  \\\n",
       "0  18.0    8  307.0  130  3504  12.0  70       1         0   \n",
       "1  15.0    8  350.0  165  3693  11.5  70       1         0   \n",
       "2  18.0    8  318.0  150  3436  11.0  70       1         0   \n",
       "3  16.0    8  304.0  150  3433  12.0  70       1         0   \n",
       "4  17.0    8  302.0  140  3449  10.5  70       1         0   \n",
       "\n",
       "                    car_name  \n",
       "0  chevrolet chevelle malibu  \n",
       "1          buick skylark 320  \n",
       "2         plymouth satellite  \n",
       "3              amc rebel sst  \n",
       "4                ford torino  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/car_mpg.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a lambda function to check if any value is only alphabetic\n",
    "df['hp'] = df['hp'].apply(lambda x: x if x.isdecimal() else np.NaN)\n",
    "df['hp'] = df['hp'].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style = \"font-size:100%;padding:10px 0px 10px 30px;font-weight: 400;font-family:serifs; letter-spacing: 2px; border: 3px solid yellow; color: brown; background-color:#d3d3d3; border-radius:30px 0px\">2.PreProcessing & Modelling</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(df_act: pd.DataFrame, df: pd.DataFrame, scale: str = \"yes\") -> pd.DataFrame:\n",
    "    \"\"\"Encodes object with Label Encoder and saves preprocessing transformers to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): This DataFrame is used for object label encoding.\n",
    "        scale (str): To Scale the data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: label Encoded dataframe\n",
    "        Simply label encodes object attributes.\n",
    "    \"\"\"\n",
    "\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Encoding the object attributes\n",
    "    label_encoders = {}  # Dictionary to store LabelEncoders\n",
    "\n",
    "    for col in df_encoded.columns:\n",
    "        if df_encoded[col].dtype == 'object':\n",
    "            \n",
    "            label_encoder = LabelEncoder()\n",
    "            \n",
    "            label_encoder.fit(df_act[col])\n",
    "            \n",
    "            label_encoders[col] = label_encoder\n",
    "            \n",
    "            df_act[col] = label_encoder.transform(df_act[col])\n",
    "            df_encoded[col] = label_encoder.transform(df_encoded[col])\n",
    "\n",
    "    # Create a pipeline with SimpleImputer and StandardScaler\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # You can choose other strategies for imputation\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(df_act)\n",
    "\n",
    "    # Fit the pipeline to the training data (df_act)\n",
    "    if scale == \"yes\":\n",
    "        df_imputed = pd.DataFrame(pipeline.transform(df_encoded), columns=df_encoded.columns)\n",
    "        print(\"Data is Imputed and scaled\")\n",
    "        print(\"-\" * 80)\n",
    "    else:\n",
    "        simp = SimpleImputer(strategy='mean')\n",
    "        simp.fit(df_act)\n",
    "        df_imputed = pd.DataFrame(simp.transform(df_encoded), columns=df_encoded.columns)\n",
    "        print(\"Data is Imputed\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    # Save LabelEncoders, Imputer, and Scaler to a pickle file\n",
    "    preprocessing_data = {\n",
    "        'label_encoders': label_encoders,\n",
    "        'imputer': pipeline.named_steps['imputer'],\n",
    "        'scaler': pipeline.named_steps['scaler']\n",
    "    }\n",
    "\n",
    "    with open('models/preprocessing_transformers.pkl', 'wb') as file:\n",
    "        pickle.dump(preprocessing_data, file)\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "\n",
    "def model_evaluation(model_score: Dict, N_SPLITS:int, idx:int=0)-> None:\n",
    "    \"\"\"Plots Model evaluation results.\n",
    "    \n",
    "    Args: \n",
    "        model_score (Dict): This Model results dictionary for a metric. \n",
    "        N_SPLITS     (int): number of folds used. \n",
    "        idx          (int): 0 for validation and 1 for test results. \n",
    " \n",
    "    Returns: \n",
    "        None \n",
    "        Simply Plots model eval results on validation data set.         \n",
    "    \"\"\"\n",
    "    \n",
    "    metric_list = ['r2-square','mae','rmse']\n",
    "    nm = 'VALIDATION'\n",
    "    metric_nm = metric_list[idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    for keys in model_score.keys():\n",
    "        ax.plot(model_score[keys]['valid'][metric_nm], label=str(keys), marker=\".\")\n",
    "           \n",
    "        \n",
    "    ax.set_title(f\"{metric_nm.upper()} scores for Each FOLD - {nm}\".upper(), fontdict=font_sub_title)\n",
    "    ax.set_xticks(np.arange(N_SPLITS))\n",
    "    ax.set_xlabel(\"FOLD\", fontdict=font_label)\n",
    "    ax.set_ylabel(f\"{metric_nm.upper()} Scores\", fontdict=font_label)\n",
    "    ax.tick_params(labelsize=16, labelcolor='brown',width = 4)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    col_name ='Model_Evaluation'+\"_\"+str(nm) +\"_\"+str(metric_nm) \n",
    "    path = \"static/model_plots/\"+col_name+\".jpg\"\n",
    "    plt.savefig(path, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def model_predict(model_dict:Dict, train_X, train_y,X_test,y_test, N_SPLITS: int, RANDOM_STATE: int)-> Dict:\n",
    "    \n",
    "    \"\"\"Gets Model evaluation results.\n",
    "    \n",
    "    Args: \n",
    "        model_dict (Dict): This is Dictinary of models to be used for prediction. \n",
    "        X     (DataFrame): Independant train data. \n",
    "        y    (DataSeries): Dependant train target data. \n",
    "        N_SPLITS    (int): Number of splits for Kfold cross validation. \n",
    "        RANDOM_STATE(int): Random state for to draw same samples. \n",
    " \n",
    "    Returns: \n",
    "        Dict : model evaluation results \n",
    "        Simply get validation results for models used on train data set.         \n",
    "    \"\"\"\n",
    "    \n",
    "    kf =KFold(n_splits=N_SPLITS,shuffle=True,random_state=RANDOM_STATE)\n",
    "\n",
    "    model_score ={}\n",
    "    trained_models = {}\n",
    "\n",
    "    for keys in model_dict.keys():   \n",
    "        \n",
    "        model_score[keys] = {}    \n",
    "        \n",
    "        model_score[keys]['valid'] = {'r2-square': [],\n",
    "                                        'mae': [],\n",
    "                                        'rmse': []\n",
    "                                        }\n",
    "        model_score[keys]['test'] = {'r2-square': [],\n",
    "                                    'mae': [],\n",
    "                                    'rmse': []\n",
    "                                    }\n",
    "        trained_models[keys] = []\n",
    "        y_test_pred = np.zeros(len(X_test))\n",
    "        \n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(train_X,train_y)):\n",
    "            X_train, X_val = train_X.iloc[train_idx], train_X.iloc[val_idx]\n",
    "            y_train, y_val = train_y.iloc[train_idx].to_numpy().ravel(), train_y.iloc[val_idx].to_numpy().ravel()\n",
    "            \n",
    "            # Each model should have its own instance\n",
    "            model = copy.deepcopy(model_dict[keys])\n",
    "            #model = model_dict[keys].__class__()\n",
    "            \n",
    "            model_fit = model.fit(X_train,y_train)\n",
    "            trained_models[keys].append(model_fit)\n",
    "                        \n",
    "            y_val_pred  = model_fit.predict(X_val)\n",
    "            model_score[keys]['valid']['r2-square'].append(metrics.r2_score(y_val,y_val_pred))\n",
    "            model_score[keys]['valid']['mae'].append(metrics.mean_absolute_error(y_val,y_val_pred))\n",
    "            model_score[keys]['valid']['rmse'].append(np.sqrt(metrics.mean_squared_error(y_val,y_val_pred)))\n",
    "            \n",
    "            y_test_pred += model_fit.predict(X_test)/N_SPLITS\n",
    "                            \n",
    "\n",
    "        model_score[keys]['test']['r2-square'].append(metrics.r2_score(y_test,y_test_pred))\n",
    "        model_score[keys]['test']['mae'].append(metrics.mean_absolute_error(y_test,y_test_pred))\n",
    "        model_score[keys]['test']['rmse'].append(np.sqrt(metrics.mean_squared_error(y_test,y_test_pred)))\n",
    "            \n",
    "            \n",
    "    mean_score = [[],[],[]]\n",
    "    print(\"-\"*34+\"R2      MAE     RMSE\"+\"-\"*14+\"R2      MAE     RMSE\")\n",
    "    for keys in model_score.keys():\n",
    "        val_r2 = np.mean(model_score[keys]['valid']['r2-square'])\n",
    "        val_mae = np.mean(model_score[keys]['valid']['mae'])\n",
    "        val_rmse = np.mean(model_score[keys]['valid']['rmse'])\n",
    "        \n",
    "        tst_r2 = np.mean(model_score[keys]['test']['r2-square'])\n",
    "        tst_mae = np.mean(model_score[keys]['test']['mae'])\n",
    "        tst_rmse = np.mean(model_score[keys]['test']['rmse'])\n",
    "        \n",
    "        print(f\"{blu}Model : {gld}{keys:>{12}} {blu}Validation : {magenta}{val_r2:.4f}, {val_mae:.4f}, {val_rmse:.4f}  |  {blu}Test : {magenta}{tst_r2:.4f}, {tst_mae:.4f}, {tst_rmse:.4f}{res}\") \n",
    "        mean_score[0].append(val_r2)\n",
    "        mean_score[1].append(val_mae)\n",
    "        mean_score[2].append(val_rmse)\n",
    "        \n",
    "\n",
    "    metric_list = ['r2-square','mae','rmse']\n",
    "    print(\"-\"*80)\n",
    "    for i in range(len(mean_score)):\n",
    "        if i == 0:\n",
    "            m_index = np.argmax(mean_score[i])\n",
    "        else:\n",
    "            m_index = np.argmin(mean_score[i])\n",
    "\n",
    "        best_model = list(model_dict.keys())[m_index]\n",
    "        best_score = mean_score[i][m_index]\n",
    "        print(f\"For Metric {gld}{metric_list[i]:>{10}} {magenta}Best Model : {best_model}   |  Best Score : {gld}{best_score:.4f}{res}\")\n",
    "        \n",
    "    return model_score, trained_models\n",
    "\n",
    "\n",
    "def pickle_model(trained_models:Dict, \n",
    "                 directory:str =\"models\",\n",
    "                 pickle_name:str=\"pickled_model\", \n",
    "                 use:str='pickle' ):\n",
    "    \n",
    "    \"\"\"Creates a directory for pickled model files and saves the pickle files\n",
    "        and also create pickle files from passed dictionary of models.\n",
    "    \n",
    "    Args: \n",
    "        trained_models    (Dict): This is Dictinary of models to be used for pickling. \n",
    "        directory    (DataFrame): Directory name for creating it. \n",
    "        pickle_name (DataSeries): Name of the pickled file of dict of models. \n",
    "        use                (int): Number of plits for Kfold cross validation. \n",
    "       \n",
    "    Returns: \n",
    "        Dict : Pickled models\n",
    "        Simply pickles model and loads the pickled model.         \n",
    "    \"\"\"\n",
    "\n",
    "    directory = \"models\"\n",
    "    parent_dir = os.getcwd()\n",
    "\n",
    "    path = os.path.join(parent_dir,directory)\n",
    "    print(path)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path=path)\n",
    "        \n",
    "    print(\"-\"*80)\n",
    "    print(f\"Directory with {red}{directory}{res} name created\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    if use == 'pickle':\n",
    "        pickle_file_path = directory+'/'+pickle_name+'.pkl'\n",
    "        # Use pickle to save the model\n",
    "        with open(pickle_file_path, 'wb') as pickle_file:\n",
    "            pickle.dump(trained_models, pickle_file)\n",
    "        \n",
    "        print(f\"Model file pickled & SAVED in directory {red}{pickle_file_path}{res}\")\n",
    "        \n",
    "        # Load the saved list of models using pickle\n",
    "        with open(pickle_file_path, 'rb') as pickle_file:\n",
    "            loaded_models_pickle = pickle.load(pickle_file)\n",
    "            \n",
    "        print(f\"{red}pickle file{res} named {pickle_name} {red}LOADED{res}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        return loaded_models_pickle\n",
    "            \n",
    "    else:\n",
    "        # Specify the file path where you want to save the models\n",
    "        joblib_file_path = directory+'/'+pickle_name+'.pkl'\n",
    "        # Use joblib to save the list of trained models to a pickle file\n",
    "        joblib.dump(trained_models, joblib_file_path)\n",
    "        print(f\"Joblib SAVED model in file path {red}{joblib_file_path}{res}\")\n",
    "        \n",
    "        # Load the saved model\n",
    "        loaded_model_job = joblib.load(joblib_file_path)\n",
    "        \n",
    "        print(f\"{red}Joblib file{res} named {pickle_name} {red}LOADED{res}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        return loaded_model_job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_plot(y_true, y_pred,best_model_name:str=\"rf_reg\")-> None:\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,6), layout=\"constrained\")\n",
    "\n",
    "    y_true = np.array(y_true).ravel()\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "\n",
    "    min_val =  min(y_true)\n",
    "    max_val =  max(y_true)\n",
    "\n",
    "    sns.scatterplot(x=y_pred,y=y_true, ax = ax[0], s=25, facecolor='#f0ab62', edgecolor='black', linewidth=1.5, label=\"Actual\")\n",
    "    ax[0].set_title(\"Regression Plot Predictions\", fontdict=font_sub_title)\n",
    "    ax[0].set_xlabel(\"mpg Predcited\", fontdict=font_label)\n",
    "    ax[0].set_ylabel(\"mpg Actual\", fontdict=font_label)\n",
    "    ax[0].tick_params(labelsize = 14, labelcolor=\"brown\", width=2)\n",
    "\n",
    "    # Add a 45-degree line\n",
    "    ax[0].plot([min_val, max_val], [min_val, max_val], color='green', linestyle='--', linewidth=2, label=\"Perfectly Predicted\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    sns.histplot(y_pred, ax =ax[1], color = \"black\", label = \"Predicted\", bins = 20)\n",
    "    sns.histplot(y_true, ax =ax[1], color = \"#f0ab62\", label = \"Actual\", bins = 20)\n",
    "    ax[1].set_title(\"Distribution Plots\", fontdict=font_sub_title)\n",
    "    ax[1].set_xlabel(\"mpg\", fontdict=font_label)\n",
    "    ax[1].set_ylabel(\"Count\", fontdict=font_label)\n",
    "    ax[1].tick_params(labelsize = 14, labelcolor=\"brown\", width=2)\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    col_name ='Reg_and_dist_plot'+' for '+best_model_name \n",
    "    path = \"static/model_plots/\"+col_name+\".jpg\"\n",
    "    plt.savefig(path, bbox_inches=\"tight\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def error_plot(y_true,y_pred,best_model_name:str=\"rf_reg\")-> None:\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,6), layout=\"constrained\")\n",
    "\n",
    "    y_true = np.array(y_true).ravel()\n",
    "    y_pred = np.array(y_pred).ravel()\n",
    "\n",
    "    y_err = y_true - y_pred\n",
    "\n",
    "    sns.scatterplot(x=y_pred,y=y_err, ax = ax, s=75, facecolor='#f0ab62', edgecolor='black', linewidth=2, label =\"error\")\n",
    "    ax.set_title(\"Error Distribution Plots\", fontdict=font_sub_title)\n",
    "    ax.set_xlabel(\"mpg Predcited Values\", fontdict=font_label)\n",
    "    ax.set_ylabel(\"Error\", fontdict=font_label)\n",
    "    ax.tick_params(labelsize = 14, labelcolor=\"brown\", width=2)\n",
    "\n",
    "    # Add a horizontal line from x = 0 to x = 10\n",
    "    ax.hlines(y=0, xmin=min(y_pred)-0.5, xmax=max(y_pred)+0.5, color='green', linestyle='--', linewidth=4, label=\"actual_line\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    col_name ='Error_plot' +' for '+best_model_name\n",
    "    path = \"static/model_plots/\"+col_name+\".jpg\"\n",
    "    plt.savefig(path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 8\n",
    "\n",
    "y_col = ['mpg']\n",
    "x_cols = [col for col in df.columns if col not in y_col]\n",
    "\n",
    "# Specify columns by data type\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "num_cols = [col for col in df.columns if col not in cat_cols+y_col]\n",
    "\n",
    "# Models to be used for prediction\n",
    "\n",
    "model_dict ={\n",
    "    'linear_reg':LinearRegression(),\n",
    "    'dt_reg' : DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
    "    'rf_reg' : RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    'histgbm_reg' : HistGradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "    'xgb_reg' : xgb.XGBRegressor(random_state=RANDOM_STATE),\n",
    "    'lgb_reg' : lgb.LGBMRegressor(random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91981\\AppData\\Local\\Temp\\ipykernel_12960\\2560275212.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_act[col] = label_encoder.transform(df_act[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Imputed\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------R2      MAE     RMSE--------------R2      MAE     RMSE\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m  linear_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8186, 2.5429, 3.2933  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8648, 2.1420, 2.6957\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      dt_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.7578, 2.6269, 3.7652  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8866, 1.6972, 2.4694\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      rf_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8546, 2.0446, 2.9303  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9200, 1.5804, 2.0745\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m histgbm_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8550, 2.0826, 2.9440  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9192, 1.5853, 2.0841\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     xgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8367, 2.2180, 3.1181  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9025, 1.7105, 2.2898\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     lgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8569, 2.1193, 2.9280  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9154, 1.6208, 2.1326\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "For Metric \u001b[1m\u001b[33m r2-square \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m0.8569\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m       mae \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.0446\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m      rmse \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m2.9280\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed = preProcess(df[x_cols],df[x_cols],scale=\"no\")\n",
    "X = df_preprocessed[x_cols]\n",
    "y = df[y_col]\n",
    "\n",
    "train_X, X_test, train_y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_score, trained_models = model_predict(model_dict=model_dict,\n",
    "              train_X= train_X,\n",
    "              train_y=train_y,\n",
    "              X_test = X_test,\n",
    "              y_test = y_test,\n",
    "              N_SPLITS=N_SPLITS,\n",
    "              RANDOM_STATE=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_encoders': {'car_name': LabelEncoder()},\n",
       " 'imputer': SimpleImputer(),\n",
       " 'scaler': StandardScaler()}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved list of models using pickle\n",
    "pickle_file_path = \"models/preprocessing_transformers.pkl\"\n",
    "with open(pickle_file_path, 'rb') as pickle_file:\n",
    "    preprocess_pickle = pickle.load(pickle_file)\n",
    "preprocess_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_encoders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>acc</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_type</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cyl   disp     hp    wt   acc  yr  origin  car_type  car_name\n",
       "0    8  307.0  130.0  3504  12.0  70       1         0        49\n",
       "1    8  350.0  165.0  3693  11.5  70       1         0        36"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed = df[x_cols].copy()\n",
    "process = 'label_encoders'\n",
    "print(process)\n",
    "for col in preprocess_pickle[process].keys():\n",
    "    df_transformed[col] = preprocess_pickle[process][col].transform(df_transformed[col])\n",
    "        \n",
    "df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputer\n",
      "----------------------------------R2      MAE     RMSE--------------R2      MAE     RMSE\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m  linear_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8186, 2.5429, 3.2933  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8648, 2.1420, 2.6957\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      dt_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.7578, 2.6269, 3.7652  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8866, 1.6972, 2.4694\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      rf_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8546, 2.0446, 2.9303  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9200, 1.5804, 2.0745\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m histgbm_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8550, 2.0826, 2.9440  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9192, 1.5853, 2.0841\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     xgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8367, 2.2180, 3.1181  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9025, 1.7105, 2.2898\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     lgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8569, 2.1193, 2.9280  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9154, 1.6208, 2.1326\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "For Metric \u001b[1m\u001b[33m r2-square \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m0.8569\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m       mae \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.0446\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m      rmse \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m2.9280\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "process = 'imputer'\n",
    "print(process)     \n",
    "df_transformed = pd.DataFrame(preprocess_pickle[process].transform(df_transformed), columns= df_transformed.columns)\n",
    "df_transformed.head(2)\n",
    "\n",
    "Xt = df_transformed[x_cols]\n",
    "yt = df[y_col]\n",
    "\n",
    "train_Xt, X_testt, train_yt, y_testt = train_test_split(Xt, yt, test_size=0.2, random_state=42)\n",
    "\n",
    "model_score, trained_models = model_predict(model_dict=model_dict,\n",
    "              train_X= train_Xt,\n",
    "              train_y=train_yt,\n",
    "              X_test = X_testt,\n",
    "              y_test = y_testt,\n",
    "              N_SPLITS=N_SPLITS,\n",
    "              RANDOM_STATE=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91981\\Desktop\\GREAT LEARNING\\FROM SCRATCH LEARNING\\PROJETCS\\regression_car_mpg_sample_project\\models\n",
      "--------------------------------------------------------------------------------\n",
      "Directory with \u001b[1m\u001b[31mmodels\u001b[0m name created\n",
      "--------------------------------------------------------------------------------\n",
      "Model file pickled & SAVED in directory \u001b[1m\u001b[31mmodels/model_file.pkl\u001b[0m\n",
      "\u001b[1m\u001b[31mpickle file\u001b[0m named model_file \u001b[1m\u001b[31mLOADED\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "0.971565576178391\n",
      "0.9199574982423983\n"
     ]
    }
   ],
   "source": [
    "best_model_name = 'rf_reg'\n",
    "loaded_model = pickle_model(trained_models=trained_models[best_model_name],\n",
    "                             directory='models',\n",
    "                             pickle_name='model_file',\n",
    "                             use='pickle')\n",
    "\n",
    "train_preds_final = np.zeros(len(train_X))\n",
    "for model in loaded_model:\n",
    "    train_preds_final+=model.predict(train_X)/N_SPLITS\n",
    "print(metrics.r2_score(train_y,train_preds_final))\n",
    "\n",
    "\n",
    "test_preds_final = np.zeros(len(X_test))\n",
    "for model in loaded_model:\n",
    "    test_preds_final+=model.predict(X_test)/N_SPLITS\n",
    "print(metrics.r2_score(y_test,test_preds_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg               23.0\n",
       "cyl                  4\n",
       "disp             115.0\n",
       "hp                95.0\n",
       "wt                2694\n",
       "acc               15.0\n",
       "yr                  75\n",
       "origin               2\n",
       "car_type             1\n",
       "car_name    audi 100ls\n",
       "Name: 177, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyl                 4.000000\n",
       "disp              115.000000\n",
       "hp                 95.000000\n",
       "wt               2694.000000\n",
       "acc                15.000000\n",
       "yr                 75.000000\n",
       "origin              2.000000\n",
       "car_type            1.000000\n",
       "car_name           17.000000\n",
       "preds_noscale      23.059375\n",
       "Name: 177, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['preds_noscale'] = train_preds_final\n",
    "train_X.loc[177]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91981\\AppData\\Local\\Temp\\ipykernel_12960\\2560275212.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_act[col] = label_encoder.transform(df_act[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Imputed and scaled\n",
      "--------------------------------------------------------------------------------\n",
      "----------------------------------R2      MAE     RMSE--------------R2      MAE     RMSE\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m  linear_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8186, 2.5429, 3.2933  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8648, 2.1420, 2.6957\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      dt_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.7581, 2.6261, 3.7622  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8870, 1.6850, 2.4652\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      rf_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8550, 2.0416, 2.9255  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9200, 1.5767, 2.0736\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m histgbm_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8549, 2.0856, 2.9448  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9192, 1.5858, 2.0843\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     xgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8367, 2.2163, 3.1184  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9026, 1.7085, 2.2881\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     lgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8556, 2.0940, 2.9393  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9165, 1.6102, 2.1193\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "For Metric \u001b[1m\u001b[33m r2-square \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m0.8556\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m       mae \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.0416\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m      rmse \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.9255\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_preprocessed = preProcess(df[x_cols],df[x_cols],scale=\"yes\")\n",
    "X_sc = df_preprocessed[x_cols]\n",
    "y_sc = df[y_col]\n",
    "\n",
    "train_X_sc, X_test_sc, train_y_sc, y_test_sc = train_test_split(X_sc, y_sc, test_size=0.2, random_state=42)\n",
    "\n",
    "model_score, trained_models = model_predict(model_dict=model_dict,\n",
    "              train_X= train_X_sc,\n",
    "              train_y=train_y_sc,\n",
    "              X_test = X_test_sc,\n",
    "              y_test = y_test_sc,\n",
    "              N_SPLITS=N_SPLITS,\n",
    "              RANDOM_STATE=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91981\\anaconda3\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>acc</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>car_type</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.498191</td>\n",
       "      <td>1.090604</td>\n",
       "      <td>0.669196</td>\n",
       "      <td>0.630870</td>\n",
       "      <td>-1.295498</td>\n",
       "      <td>-1.627426</td>\n",
       "      <td>-0.715145</td>\n",
       "      <td>-1.062235</td>\n",
       "      <td>-1.113745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.498191</td>\n",
       "      <td>1.503514</td>\n",
       "      <td>1.586599</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>-1.477038</td>\n",
       "      <td>-1.627426</td>\n",
       "      <td>-0.715145</td>\n",
       "      <td>-1.062235</td>\n",
       "      <td>-1.259185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cyl      disp        hp        wt       acc        yr    origin  \\\n",
       "0  1.498191  1.090604  0.669196  0.630870 -1.295498 -1.627426 -0.715145   \n",
       "1  1.498191  1.503514  1.586599  0.854333 -1.477038 -1.627426 -0.715145   \n",
       "\n",
       "   car_type  car_name  \n",
       "0 -1.062235 -1.113745  \n",
       "1 -1.062235 -1.259185  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = 'scaler'\n",
    "print(process)     \n",
    "df_transformed_sc = pd.DataFrame(preprocess_pickle[process].transform(df_transformed), columns= df_transformed.columns)\n",
    "df_transformed_sc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------R2      MAE     RMSE--------------R2      MAE     RMSE\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m  linear_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8186, 2.5429, 3.2933  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8648, 2.1420, 2.6957\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      dt_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.7581, 2.6261, 3.7622  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.8870, 1.6850, 2.4652\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m      rf_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8550, 2.0416, 2.9255  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9200, 1.5767, 2.0736\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m histgbm_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8549, 2.0856, 2.9448  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9192, 1.5858, 2.0843\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     xgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8367, 2.2163, 3.1184  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9026, 1.7085, 2.2881\u001b[0m\n",
      "\u001b[1m\u001b[34mModel : \u001b[1m\u001b[33m     lgb_reg \u001b[1m\u001b[34mValidation : \u001b[1m\u001b[35m0.8556, 2.0940, 2.9393  |  \u001b[1m\u001b[34mTest : \u001b[1m\u001b[35m0.9165, 1.6102, 2.1193\u001b[0m\n",
      "--------------------------------------------------------------------------------\n",
      "For Metric \u001b[1m\u001b[33m r2-square \u001b[1m\u001b[35mBest Model : lgb_reg   |  Best Score : \u001b[1m\u001b[33m0.8556\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m       mae \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.0416\u001b[0m\n",
      "For Metric \u001b[1m\u001b[33m      rmse \u001b[1m\u001b[35mBest Model : rf_reg   |  Best Score : \u001b[1m\u001b[33m2.9255\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Xt_sc = df_transformed_sc[x_cols]\n",
    "yt_sc = df[y_col]\n",
    "\n",
    "train_Xt_sc, X_testt_sc, train_yt_sc, y_testt_sc = train_test_split(Xt_sc, yt_sc, test_size=0.2, random_state=42)\n",
    "\n",
    "model_score, trained_models = model_predict(model_dict=model_dict,\n",
    "              train_X= train_Xt_sc,\n",
    "              train_y=train_yt_sc,\n",
    "              X_test = X_testt_sc,\n",
    "              y_test = y_testt_sc,\n",
    "              N_SPLITS=N_SPLITS,\n",
    "              RANDOM_STATE=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(model_score=model_score, N_SPLITS=N_SPLITS, idx=0)\n",
    "model_evaluation(model_score=model_score, N_SPLITS=N_SPLITS, idx=1)\n",
    "model_evaluation(model_score=model_score, N_SPLITS=N_SPLITS, idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91981\\Desktop\\GREAT LEARNING\\FROM SCRATCH LEARNING\\PROJETCS\\regression_car_mpg_sample_project\\models\n",
      "--------------------------------------------------------------------------------\n",
      "Directory with \u001b[1m\u001b[31mmodels\u001b[0m name created\n",
      "--------------------------------------------------------------------------------\n",
      "Model file pickled & SAVED in directory \u001b[1m\u001b[31mmodels/model_file.pkl\u001b[0m\n",
      "\u001b[1m\u001b[31mpickle file\u001b[0m named model_file \u001b[1m\u001b[31mLOADED\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_model_name = 'rf_reg'\n",
    "loaded_model = pickle_model(trained_models=trained_models[best_model_name],\n",
    "                             directory='models',\n",
    "                             pickle_name='model_file',\n",
    "                             use='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715935872657938\n",
      "0.9200303414443791\n"
     ]
    }
   ],
   "source": [
    "train_preds_final = np.zeros(len(train_X_sc))\n",
    "for model in loaded_model:\n",
    "    train_preds_final+=model.predict(train_X_sc)/N_SPLITS\n",
    "print(metrics.r2_score(train_y_sc,train_preds_final))\n",
    "\n",
    "\n",
    "test_preds_final = np.zeros(len(X_test_sc))\n",
    "for model in loaded_model:\n",
    "    test_preds_final+=model.predict(X_test_sc)/N_SPLITS\n",
    "print(metrics.r2_score(y_test_sc,test_preds_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg                  16.0\n",
       "cyl                     8\n",
       "disp                304.0\n",
       "hp                  150.0\n",
       "wt                   3433\n",
       "acc                  12.0\n",
       "yr                     70\n",
       "origin                  1\n",
       "car_type                0\n",
       "car_name    amc rebel sst\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyl               8.000000\n",
       "disp            304.000000\n",
       "hp              150.000000\n",
       "wt             3433.000000\n",
       "acc              12.000000\n",
       "yr               70.000000\n",
       "origin            1.000000\n",
       "car_type          0.000000\n",
       "car_name         14.000000\n",
       "train_preds      15.830375\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['train_preds'] = train_preds_final\n",
    "train_X.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_plot(train_y, train_preds_final, best_model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_plot(train_y, train_preds_final, best_model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
